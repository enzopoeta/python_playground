{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NAIVE BAYES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseado no teorema de bayes (análise probabilistica)\n",
    "\n",
    "Aplicações mais comuns :\n",
    "\n",
    "- Detecção de SPAN\n",
    "- Detecção de emoções em frases\n",
    "- Separação de documentos\n",
    "\n",
    "O naive bayes a partir da tabela de dados previsores gera uma tabela de probabilidades que é usada como base para classificar novos dados.\n",
    "\n",
    "Vantagens :\n",
    "\n",
    "- Rápido se comparado a abordagens mais complexas ( Ex: redes neurais )\n",
    "- Simples\n",
    "- Capaz de tabalhar com altas dimensões (atributos)\n",
    "- Boas previsões em bases de dados pequenas ( 400 - 1000 registros)\n",
    "\n",
    "Desvantagens :\n",
    "- Presume que os atributos previsores são totalmente independentes, o que nem sempre é verdade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "# carregando a base de dados de censo\n",
    "base = pd.read_csv('../../res/census.csv')\n",
    "base.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados de previsao e classificacao\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classificadores = base.iloc[:, 14].values\n",
    "\n",
    "#gerando uma copia dos dados originais para fazer mais testes abaixo\n",
    "previsores_escalonados=previsores.copy()\n",
    "\n",
    "\n",
    "#efetuando correcoes nos dados do censo\n",
    "\n",
    "#transformando dados categorios da base em dados discretos\n",
    "\n",
    "labelencoder_prev = LabelEncoder()\n",
    "previsores[:, 1] = labelencoder_prev.fit_transform(previsores[:, 1])\n",
    "previsores[:, 3] = labelencoder_prev.fit_transform(previsores[:, 3])\n",
    "previsores[:, 5] = labelencoder_prev.fit_transform(previsores[:, 5])\n",
    "previsores[:, 6] = labelencoder_prev.fit_transform(previsores[:, 6])\n",
    "previsores[:, 7] = labelencoder_prev.fit_transform(previsores[:, 7])\n",
    "previsores[:, 8] = labelencoder_prev.fit_transform(previsores[:, 8])\n",
    "previsores[:, 9] = labelencoder_prev.fit_transform(previsores[:, 9])\n",
    "previsores[:, 13] = labelencoder_prev.fit_transform(previsores[:, 13])\n",
    "\n",
    "preprocess = make_column_transformer(( OneHotEncoder(categories='auto'), [1,3,5,6,7,8,9,13] ),remainder=\"passthrough\") \n",
    "previsores = preprocess.fit_transform(previsores).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizando estatisticas dos dados nao discretos antes do escalonamento\n",
      "\n",
      "coluna  0 \n",
      "\n",
      "13\n",
      "2174\n",
      "742.3333333333334\n",
      "1024956.222222222\n",
      "\n",
      "\n",
      "coluna  1 \n",
      "\n",
      "0\n",
      "13\n",
      "8.666666666666666\n",
      "37.55555555555556\n",
      "\n",
      "\n",
      "coluna  2 \n",
      "\n",
      "0\n",
      "40\n",
      "16.333333333333332\n",
      "293.5555555555556\n",
      "\n",
      "\n",
      "\n",
      "Visualizando estatisticas dos dados nao discretos depois do escalonamento\n",
      "\n",
      "coluna  0 \n",
      "\n",
      "4.348043480434804\n",
      "160.0\n",
      "81.31329340504288\n",
      "4039.403634595381\n",
      "\n",
      "\n",
      "coluna  1 \n",
      "\n",
      "0.0\n",
      "160.0\n",
      "61.49659863945578\n",
      "4951.418390485446\n",
      "\n",
      "\n",
      "coluna  2 \n",
      "\n",
      "0.0\n",
      "106.66666666666667\n",
      "62.08616780045352\n",
      "2049.5205187139104\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# padronizando os valores nao discretos da copia dos previsores ( nao deve ser feito para todos os parametros sob risco de degradar a precisao do algoritimo)\n",
    "\n",
    "#o min max scaler foi mais interessante para este caso\n",
    "scaler = MinMaxScaler(feature_range=(0, 200))\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#transformando dados categorios da copia da base em dados discretos\n",
    "labelencoder_prev = LabelEncoder()\n",
    "previsores_escalonados[:, 1] = labelencoder_prev.fit_transform(previsores_escalonados[:, 1])\n",
    "previsores_escalonados[:, 3] = labelencoder_prev.fit_transform(previsores_escalonados[:, 3])\n",
    "previsores_escalonados[:, 5] = labelencoder_prev.fit_transform(previsores_escalonados[:, 5])\n",
    "previsores_escalonados[:, 6] = labelencoder_prev.fit_transform(previsores_escalonados[:, 6])\n",
    "previsores_escalonados[:, 7] = labelencoder_prev.fit_transform(previsores_escalonados[:, 7])\n",
    "previsores_escalonados[:, 8] = labelencoder_prev.fit_transform(previsores_escalonados[:, 8])\n",
    "previsores_escalonados[:, 9] = labelencoder_prev.fit_transform(previsores_escalonados[:, 9])\n",
    "previsores_escalonados[:, 13] = labelencoder_prev.fit_transform(previsores_escalonados[:, 13])\n",
    "\n",
    "\n",
    "print(\"\\nVisualizando estatisticas dos dados nao discretos antes do escalonamento\\n\")\n",
    "for x in range(3):\n",
    "    print('coluna ',x,\"\\n\")\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].min())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].max())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].mean())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].var())\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "#padronizando dados nao discretos da copia da base original (testes feitos de varias maneiras para daterminar o melhor resultado)\n",
    "#previsores_escalonados[:,[2,4,10,11,12]] = scaler.fit_transform(previsores_escalonados[:,[2,4,10,11,12]])\n",
    "\n",
    "#testes com poucas colunas escalonadas\n",
    "previsores_escalonados[:,[12]] = scaler.fit_transform(previsores_escalonados[:,[12]])\n",
    "previsores_escalonados[:,[10]] = scaler.fit_transform(previsores_escalonados[:,[10]])\n",
    "previsores_escalonados[:,[4]] = scaler.fit_transform(previsores_escalonados[:,[4]])\n",
    "\n",
    "print(\"\\nVisualizando estatisticas dos dados nao discretos depois do escalonamento\\n\")\n",
    "for x in range(3):\n",
    "    print('coluna ',x,\"\\n\")\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].min())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].max())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].mean())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].var())\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "#fazendo o one hot encoder para a copia da base (para os valores discretos)\n",
    "preprocess = make_column_transformer(( OneHotEncoder(categories='auto'), [1,3,5,6,7,8,9,13] ),remainder=\"passthrough\") \n",
    "previsores_escalonados = preprocess.fit_transform(previsores_escalonados).toarray()\n",
    "\n",
    "\n",
    "#separando os valores de teste e treinamento  para os previsores escalonados e nao escalonados\n",
    "previsores_treinamento, previsores_teste, classificadores_treinamento1, classificadores_teste1 = train_test_split(previsores, classificadores, test_size=0.15, random_state=0)\n",
    "previsores_escalonados_treinamento, previsores_escalonados_teste, classificadores_treinamento, classificadores_teste = train_test_split(previsores_escalonados, classificadores, test_size=0.15, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciando o naive bayes com o scikit\n",
    "classificador = GaussianNB(priors=(.75,.25))\n",
    "classificador.fit(previsores_escalonados_treinamento, classificadores_treinamento)\n",
    "\n",
    "# rodando previsoes com o dados de teste (copia)\n",
    "previsoes_dados_escalonados = classificador.predict(previsores_escalonados_teste)\n",
    "\n",
    "# fazendo o fit com os dados normais\n",
    "classificador.fit(previsores_treinamento, classificadores_treinamento1)\n",
    "previsoes = classificador.predict(previsores_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão dados normais / escalonados :\n",
      "\n",
      "0.7950870010235415 / 0.7985670419651996\n",
      "\n",
      "Matriz de confusão dados normais / escalonados:\n",
      "\n",
      "[[3515  178]\n",
      " [ 823  369]]\n",
      "\n",
      "\n",
      "[[3565  128]\n",
      " [ 856  336]]\n",
      "\n",
      "Report dados normais / escalonados:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.81      0.95      0.88      3693\n",
      "        >50K       0.67      0.31      0.42      1192\n",
      "\n",
      "    accuracy                           0.80      4885\n",
      "   macro avg       0.74      0.63      0.65      4885\n",
      "weighted avg       0.78      0.80      0.77      4885\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.81      0.97      0.88      3693\n",
      "        >50K       0.72      0.28      0.41      1192\n",
      "\n",
      "    accuracy                           0.80      4885\n",
      "   macro avg       0.77      0.62      0.64      4885\n",
      "weighted avg       0.79      0.80      0.76      4885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testes dessa instancia algoritimo\n",
    "\n",
    "# o dado de precisao per se nao quer dizer muita coisa e preciso verificar outras metricas\n",
    "precisao_escalonados = accuracy_score(classificadores_teste, previsoes_dados_escalonados)\n",
    "precisao = accuracy_score(classificadores_teste1, previsoes)\n",
    "\n",
    "# uma dessas metricas eh a matriz de confusao ... ela e capaz de mostrar o desempenho do algoritimo para cada classe \n",
    "matriz_escalonados = confusion_matrix(classificadores_teste, previsoes_dados_escalonados)\n",
    "matriz = confusion_matrix(classificadores_teste1, previsoes)\n",
    "\n",
    "#o scikit tambem possui uma classe utilitaria que prove um report mais detalhado...\n",
    "report_escalonados = classification_report(classificadores_teste, previsoes_dados_escalonados)\n",
    "report = classification_report(classificadores_teste1, previsoes)\n",
    "\n",
    "print(\"Precisão dados normais / escalonados :\\n\")\n",
    "print(precisao,'/',precisao_escalonados)\n",
    "print(\"\\nMatriz de confusão dados normais / escalonados:\\n\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "print(matriz_escalonados)\n",
    "print(\"\\nReport dados normais / escalonados:\\n\")\n",
    "print (report)\n",
    "print(\"\\n\")\n",
    "print (report_escalonados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**TODO :Verificar a base de treinamento para melhorar a distribuicao das classes e verificar se ha alguma melhora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
