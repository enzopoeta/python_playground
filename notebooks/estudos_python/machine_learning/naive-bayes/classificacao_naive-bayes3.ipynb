{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NAIVE BAYES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseado no teorema de bayes (análise probabilistica)\n",
    "\n",
    "Aplicações mais comuns :\n",
    "\n",
    "- Detecção de SPAN\n",
    "- Detecção de emoções em frases\n",
    "- Separação de documentos\n",
    "\n",
    "O naive bayes a partir da tabela de dados previsores gera uma tabela de probabilidades que é usada como base para classificar novos dados.\n",
    "\n",
    "Vantagens :\n",
    "\n",
    "- Rápido se comparado a abordagens mais complexas ( Ex: redes neurais )\n",
    "- Simples\n",
    "- Capaz de tabalhar com altas dimensões (atributos)\n",
    "- Boas previsões em bases de dados pequenas ( 400 - 1000 registros)\n",
    "\n",
    "Desvantagens :\n",
    "- Presume que os atributos previsores são totalmente independentes, o que nem sempre é verdade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# carregando a base de dados de censo\n",
    "base = pd.read_csv('../../res/census.csv')\n",
    "base.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados de previsao e classificacao\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classificadores = base.iloc[:, 14].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#efetuando correcoes nos dados do censo\n",
    "\n",
    "#transformando dados categorios da base em dados discretos\n",
    "\n",
    "labelencoder_prev = LabelEncoder()\n",
    "previsores[:, 1] = labelencoder_prev.fit_transform(previsores[:, 1])\n",
    "previsores[:, 3] = labelencoder_prev.fit_transform(previsores[:, 3])\n",
    "previsores[:, 5] = labelencoder_prev.fit_transform(previsores[:, 5])\n",
    "previsores[:, 6] = labelencoder_prev.fit_transform(previsores[:, 6])\n",
    "previsores[:, 7] = labelencoder_prev.fit_transform(previsores[:, 7])\n",
    "previsores[:, 8] = labelencoder_prev.fit_transform(previsores[:, 8])\n",
    "previsores[:, 9] = labelencoder_prev.fit_transform(previsores[:, 9])\n",
    "previsores[:, 13] = labelencoder_prev.fit_transform(previsores[:, 13])\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "preprocess = make_column_transformer(( OneHotEncoder(categories='auto'), [1,3,5,6,7,8,9,13] ),remainder=\"passthrough\") \n",
    "previsores = preprocess.fit_transform(previsores).toarray()\n",
    "\n",
    "#print(previsores)\n",
    "#deprecated\n",
    "#onehotencoder = OneHotEncoder(categorical_features = [1,3,5,6,7,8,9,13])\n",
    "#previsores = onehotencoder.fit_transform(previsores).toarray()\n",
    "#print(previsores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previsores escalonados treinamento /teste  (27676, 108) (4885, 108)\n",
      "classificadores treinamento /teste  (27676,) (4885,)\n"
     ]
    }
   ],
   "source": [
    "# padronizando os valores dos previsores ( nao deve ser feito para todos os parametros sob risco de degradar a performance do algoritimo)\n",
    "scaler = StandardScaler()\n",
    "previsores_escalonados = scaler.fit_transform(previsores)\n",
    "\n",
    "\n",
    "\n",
    "#separando os valores de teste e treinamento \n",
    "previsores_escalonados_treinamento, previsores_escalonados_teste, classificadores_treinamento, classificadores_teste = train_test_split(previsores_escalonados, classificadores, test_size=0.15, random_state=0)\n",
    "\n",
    "print (\"previsores escalonados treinamento /teste \",previsores_escalonados_treinamento.shape,previsores_escalonados_teste.shape)\n",
    "print (\"classificadores treinamento /teste \",classificadores_treinamento.shape,classificadores_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciando o naive bayes com o scikit\n",
    "classificador = GaussianNB()\n",
    "classificador.fit(previsores_escalonados_treinamento, classificadores_treinamento)\n",
    "\n",
    "# rodando previsoes com o dado de teste\n",
    "previsoes_dados_escalonados = classificador.predict(previsores_escalonados_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão:\n",
      "\n",
      "0.4767656090071648\n",
      "\n",
      "Matriz de confusão:\n",
      "\n",
      "[[1172 2521]\n",
      " [  35 1157]]\n",
      "\n",
      "Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.97      0.32      0.48      3693\n",
      "        >50K       0.31      0.97      0.48      1192\n",
      "\n",
      "    accuracy                           0.48      4885\n",
      "   macro avg       0.64      0.64      0.48      4885\n",
      "weighted avg       0.81      0.48      0.48      4885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testes dessa instancia algoritimo\n",
    "\n",
    "# o dado de precisao per se nao quer dizer muita coisa e preciso verificar outras metricas\n",
    "precisao = accuracy_score(classificadores_teste, previsoes_dados_escalonados)\n",
    "\n",
    "# uma dessas metricas eh a matriz de confusao ... ela e capaz de mostrar o desempenho do algoritimo para cada classe \n",
    "matriz = confusion_matrix(classificadores_teste, previsoes_dados_escalonados)\n",
    "\n",
    "#o scikit tambem possui uma classe utilitaria que prove um report mais detalhado...\n",
    "report = classification_report(classificadores_teste, previsoes_dados_escalonados)\n",
    "\n",
    "print(\"Precisão:\\n\")\n",
    "print(precisao)\n",
    "print(\"\\nMatriz de confusão:\\n\")\n",
    "print(matriz)\n",
    "print(\"\\nReport:\\n\")\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
