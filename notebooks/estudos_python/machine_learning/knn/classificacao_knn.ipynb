{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN (k nearest neighbor)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprendizado baseado em instâncias. Para determinar classe a qual pertence um novo dado o algoritmo procura traçar uma “distância” entre este novo ponto e os seus K vizinhos mais próximos para fazer a classificação.\n",
    "\n",
    "\n",
    "Características :\n",
    "\n",
    "O por ser baseado em instâncias o  KNN é um algoritmo que não precisa de treinamento (e portanto não gera um modelo). Quando é chamado para fazer uma  previsão ou classificação o algoritmo busca os dados do dataset de “treino” e é executado de maneira lazy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# carregando a base de dados de censo\n",
    "base = pd.read_csv('../../res/census.csv')\n",
    "base.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados de previsao e classificacao\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classificadores = base.iloc[:, 14].values\n",
    "\n",
    "#gerando uma copia dos dados originais para fazer mais testes abaixo\n",
    "previsores_escalonados=previsores.copy()\n",
    "\n",
    "\n",
    "#efetuando correcoes nos dados do censo\n",
    "\n",
    "#transformando dados categorios da base em dados discretos\n",
    "\n",
    "labelencoder_prev = LabelEncoder()\n",
    "previsores[:, 1] = labelencoder_prev.fit_transform(previsores[:, 1])\n",
    "previsores[:, 3] = labelencoder_prev.fit_transform(previsores[:, 3])\n",
    "previsores[:, 5] = labelencoder_prev.fit_transform(previsores[:, 5])\n",
    "previsores[:, 6] = labelencoder_prev.fit_transform(previsores[:, 6])\n",
    "previsores[:, 7] = labelencoder_prev.fit_transform(previsores[:, 7])\n",
    "previsores[:, 8] = labelencoder_prev.fit_transform(previsores[:, 8])\n",
    "previsores[:, 9] = labelencoder_prev.fit_transform(previsores[:, 9])\n",
    "previsores[:, 13] = labelencoder_prev.fit_transform(previsores[:, 13])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizando estatisticas dos dados nao discretos antes do escalonamento\n",
      "\n",
      "coluna  0 \n",
      "\n",
      "13\n",
      "2174\n",
      "742.3333333333334\n",
      "1024956.222222222\n",
      "\n",
      "\n",
      "coluna  1 \n",
      "\n",
      "0\n",
      "13\n",
      "8.666666666666666\n",
      "37.55555555555556\n",
      "\n",
      "\n",
      "coluna  2 \n",
      "\n",
      "0\n",
      "40\n",
      "16.333333333333332\n",
      "293.5555555555556\n",
      "\n",
      "\n",
      "\n",
      "Visualizando estatisticas dos dados nao discretos depois do escalonamento\n",
      "\n",
      "coluna  0 \n",
      "\n",
      "-0.035429446972779874\n",
      "1.1347387637961852\n",
      "0.4159207373469685\n",
      "0.26398513020240394\n",
      "\n",
      "\n",
      "coluna  1 \n",
      "\n",
      "-2.222153121346444\n",
      "1.1347387637961852\n",
      "-0.4111116137030442\n",
      "1.9132836891763105\n",
      "\n",
      "\n",
      "coluna  2 \n",
      "\n",
      "-0.42005962401595\n",
      "-0.035429446972779874\n",
      "-0.20046985151586794\n",
      "0.026144545620963824\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# padronizando os valores nao discretos da copia dos previsores ( nao deve ser feito para todos os parametros sob risco de degradar a precisao do algoritimo)\n",
    "\n",
    "#o min max scaler foi mais interessante para este caso\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#transformando dados categorios da copia da base em dados discretos\n",
    "labelencoder_prev = LabelEncoder()\n",
    "previsores_escalonados[:, 1] = labelencoder_prev.fit_transform(previsores_escalonados[:, 1])\n",
    "previsores_escalonados[:, 3] = labelencoder_prev.fit_transform(previsores_escalonados[:, 3])\n",
    "previsores_escalonados[:, 5] = labelencoder_prev.fit_transform(previsores_escalonados[:, 5])\n",
    "previsores_escalonados[:, 6] = labelencoder_prev.fit_transform(previsores_escalonados[:, 6])\n",
    "previsores_escalonados[:, 7] = labelencoder_prev.fit_transform(previsores_escalonados[:, 7])\n",
    "previsores_escalonados[:, 8] = labelencoder_prev.fit_transform(previsores_escalonados[:, 8])\n",
    "previsores_escalonados[:, 9] = labelencoder_prev.fit_transform(previsores_escalonados[:, 9])\n",
    "previsores_escalonados[:, 13] = labelencoder_prev.fit_transform(previsores_escalonados[:, 13])\n",
    "\n",
    "\n",
    "print(\"\\nVisualizando estatisticas dos dados nao discretos antes do escalonamento\\n\")\n",
    "for x in range(3):\n",
    "    print('coluna ',x,\"\\n\")\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].min())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].max())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].mean())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].var())\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "#escalonando os previsores da copia dos dados\n",
    "previsores_escalonados = scaler.fit_transform(previsores_escalonados)\n",
    "\n",
    "print(\"\\nVisualizando estatisticas dos dados nao discretos depois do escalonamento\\n\")\n",
    "for x in range(3):\n",
    "    print('coluna ',x,\"\\n\")\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].min())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].max())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].mean())\n",
    "    print(previsores_escalonados[:,[4,10,12]][x].var())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "labelencoder_classe = LabelEncoder()\n",
    "classificadores = labelencoder_classe.fit_transform(classificadores)\n",
    "\n",
    "\n",
    "\n",
    "#separando os valores de teste e treinamento  para os previsores escalonados e nao escalonados\n",
    "previsores_treinamento, previsores_teste, classificadores_treinamento1, classificadores_teste1 = train_test_split(previsores, classificadores, test_size=0.15, random_state=0)\n",
    "previsores_escalonados_treinamento, previsores_escalonados_teste, classificadores_treinamento, classificadores_teste = train_test_split(previsores_escalonados, classificadores, test_size=0.15, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciando o naive bayes com o scikit\n",
    "classificador = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2,n_jobs=2)\n",
    "classificador.fit(previsores_escalonados_treinamento, classificadores_treinamento)\n",
    "\n",
    "# rodando previsoes com o dados de teste (copia)\n",
    "previsoes_dados_escalonados = classificador.predict(previsores_escalonados_teste)\n",
    "\n",
    "# fazendo o fit com os dados normais\n",
    "classificador.fit(previsores_treinamento, classificadores_treinamento1)\n",
    "previsoes = classificador.predict(previsores_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão dados normais / escalonados :\n",
      "\n",
      "0.7746161719549641 / 0.8219037871033776\n",
      "\n",
      "Matriz de confusão dados normais / escalonados:\n",
      "\n",
      "[[3406  287]\n",
      " [ 814  378]]\n",
      "\n",
      "\n",
      "[[3331  362]\n",
      " [ 508  684]]\n",
      "\n",
      "Report dados normais / escalonados:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86      3693\n",
      "           1       0.57      0.32      0.41      1192\n",
      "\n",
      "    accuracy                           0.77      4885\n",
      "   macro avg       0.69      0.62      0.63      4885\n",
      "weighted avg       0.75      0.77      0.75      4885\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      3693\n",
      "           1       0.65      0.57      0.61      1192\n",
      "\n",
      "    accuracy                           0.82      4885\n",
      "   macro avg       0.76      0.74      0.75      4885\n",
      "weighted avg       0.82      0.82      0.82      4885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testes dessa instancia algoritimo\n",
    "\n",
    "# o dado de precisao per se nao quer dizer muita coisa e preciso verificar outras metricas\n",
    "precisao_escalonados = accuracy_score(classificadores_teste, previsoes_dados_escalonados)\n",
    "precisao = accuracy_score(classificadores_teste1, previsoes)\n",
    "\n",
    "# uma dessas metricas eh a matriz de confusao ... ela e capaz de mostrar o desempenho do algoritimo para cada classe \n",
    "matriz_escalonados = confusion_matrix(classificadores_teste, previsoes_dados_escalonados)\n",
    "matriz = confusion_matrix(classificadores_teste1, previsoes)\n",
    "\n",
    "#o scikit tambem possui uma classe utilitaria que prove um report mais detalhado...\n",
    "report_escalonados = classification_report(classificadores_teste, previsoes_dados_escalonados)\n",
    "report = classification_report(classificadores_teste1, previsoes)\n",
    "\n",
    "print(\"Precisão dados normais / escalonados :\\n\")\n",
    "print(precisao,'/',precisao_escalonados)\n",
    "print(\"\\nMatriz de confusão dados normais / escalonados:\\n\")\n",
    "print(matriz)\n",
    "print(\"\\n\")\n",
    "print(matriz_escalonados)\n",
    "print(\"\\nReport dados normais / escalonados:\\n\")\n",
    "print (report)\n",
    "print(\"\\n\")\n",
    "print (report_escalonados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**TODO :Verificar a base de treinamento para melhorar a distribuicao das classes e verificar se ha alguma melhora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
